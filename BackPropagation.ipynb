{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is detail decoding of Andrez Karpathy lecture on BackPropagation with my comments/explaination on every step.\n",
    "\n",
    "import torch # for converting the data to tensor and to leverage PyTorch's capabilities for numerical operations \n",
    "import torch.nn.functional as F # and compatibility of torch tensors NN models\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline \n",
    "# it will auto display the output of matplotlib without writing plt.show() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32033\n",
      "15\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "print(len(words))\n",
    "print(max(len(w) for w in words)) # Printing the number of characters in longest word\n",
    "print(words[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))# join/combine the words in a set , so it will become like a mix of characters\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}# for i,s in enumerate/iterate char, s(char) is assigned to index i plus 1 bcoz index 0 is char period(.)\n",
    "stoi['.'] = 0 # index 0 is char period(.)\n",
    "itos = {i:s for s,i in stoi.items()} # once we assign indexes to chars, we can now reverse the key value pair, so that index becomes key and char becomes value\n",
    "vocab_size = len(itos) # how many key value pair created\n",
    "print(itos)\n",
    "print(vocab_size)# it gave output 27 meaning it has all the chars of alphabet (26) plus 1 period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182580, 3]) torch.Size([182580])\n",
      "torch.Size([22767, 3]) torch.Size([22767])\n",
      "torch.Size([22799, 3]) torch.Size([22799])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "\n",
    "def build_dataset(words):  #this function takes words as input\n",
    "  X, Y = [], [] # here we created 2 empty list X and Y, X we use for our input data and Y will guess the output( in form of index)\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size # creating a list named context with size of block size and each element value as 0 ( [0,0,0] )\n",
    "    for ch in w + '.': # for char in words in names.txt adn plus period char\n",
    "      ix = stoi[ch] # Using stoi function it will iterate the value/index of each char(1 at a time) and store it in variable\n",
    "      X.append(context)# here the empty list of X has now become [0,0,0]\n",
    "      Y.append(ix)# here the empty list of Y has now become the value of variable ix ( Example char d is assigned the value 5\n",
    "                  # so now in the Y list it will become [5], instead of empty list )\n",
    "      context = context[1:] + [ix] # now as we maintaining the block size of 3 if we adding new data , we let go the index 0 data\n",
    "                                 # so now context is [0,0,5], it goes like as follows\n",
    "                                #X = [0,0,0], Y= [5]\n",
    "                                #X = [0,0,5], Y= [9]\n",
    "                                #X = [0,5,9], Y= [21] and so on\n",
    "  X = torch.tensor(X)#converting the data to tensor is to leverage PyTorch's capabilities for numerical operations\n",
    "  Y = torch.tensor(Y)#and compatibility with neural network models\n",
    "  print(X.shape, Y.shape) #will print let say for Xtr,Ytr as torch.Size([182661, 3]) torch.Size([182661])\n",
    "                                        # meaning its 2 dimensional tensor with 182661 rows and 3 columns/blocksize\n",
    "  return X, Y\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80% \n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok biolerplate done, now we get to the action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients, will have more understanding later\n",
    "def cmp(s, dt, t): # contains 3 parameters\n",
    "  ex = torch.all(dt == t.grad).item() # dt is a pytorch tensor getting compared with t ,a tensor that change with gradient adjustment\n",
    "                                      # .item() converts tensor output to python output , in this case boolean output\n",
    "  app = torch.allclose(dt, t.grad) # checks if the both tensors are approx. equal, giving it some numerical tolernce result in boolean\n",
    "  maxdiff = (dt - t.grad).abs().max().item() # calculated the absolute diff between 2 tensors\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')\n",
    "    # results will be printed in string f\n",
    "    # it will printed as counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
    "    # s in this case is counts_sum_inv , 15s meeans char can be upto 15 in len, 5s means 5 in len(false has 5 char)\n",
    "    # {s:15s} means string s with max char 15 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors,embedding vectors are numerical representations of characters\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP,hidden layer is an intermediate layer between the input and output layers\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)#vocab_size already declared in begining\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "                                                                #this part commonly used to initialize weights in neural networks\n",
    "                                               #It is designed to provide a reasonable range for the weights, promoting stable training.\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN(batchNormalisation)\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0 #The shape (1, n_hidden) indicates that it's a row vector with n_hidden elements.\n",
    "                                             #+ 1.0: This part adds 1.0 to each element of the tensor,it helps set an initial value for the bias that is not too close to zero\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total(The nelement() is predefined method is useful when you need to know the total size of a tensor)\n",
    "                                            #Parameters are the learnable components of a model, such as weights and biases\n",
    "for p in parameters:\n",
    "  p.requires_grad = True # attribute of a PyTorch tensor that indicates whether the tensor should track operations for gradient computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 #created minibatch, representing the number of examples in each minibatch(32)\n",
    "                #Minibatches are subsets of the larger dataset that are used for training a machine learning model. \n",
    "                #A smaller batch size is often used to perform gradient descent in a more computationally efficient way.\n",
    "n = batch_size # a shorter variable n for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g) #generator=g argument specifies the random number generator (g in this case)\n",
    " #generates a random tensor ix containing batch_size indices. The indices are sampled uniformly at random from the range [0, Xtr.shape[0])                \n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # The minibatch Xb consists of input examples, and Yb consists of corresponding target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4922, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors where each row represents the embedding vector for a unique character of mini batch\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors to make then suitable to form linear transformation,and putting those vectors/tensors into new dimension called embcat\n",
    "                                    # -1 means letting pytorch decide whatever size require to reshape vectors correctly\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation and performing linear transformation on the concatenated embedding vectors\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)#bnmeani, is a tensor containing the mean value for each element along the first dimension (across the minibatch) \n",
    "# keepdim =\"true\" means it will retain back same size/dimensions after sum, it is required cozof limitation of torch to collapse the dimension during summing \n",
    "bndiff = hprebn - bnmeani #differences between each pre-activation value and its mean across the minibatch\n",
    "bndiff2 = bndiff**2 # squaring up the difference to make it more noticable/obvious\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n) which adjusts the variance calculation for unbiased estimation.\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5 # Adding the small constant 1e-5 to avoid division by zero and to ensure numerical stability\n",
    "#bnvar_inv, is a tensor containing the reciprocal of the square root of the adjusted variance\n",
    "bnraw = bndiff * bnvar_inv #bnraw, is a tensor containing the batch-normalized pre-activation values\n",
    "hpreact = bngain * bnraw + bnbias #batch-normalized pre-activation values with learned scaling and shifting parameters\n",
    "\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer,  tanh function squashes its input values to the range [-1, 1]\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values #logit_maxes contains the maximum values along each row of the logits(they are raw output layer without any function like tanh)\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability,this subtracts the maximum values from each element of the tensor logits\n",
    "counts = norm_logits.exp() #math.exp(x) exponentiates the number 2. The result is e**2 , which is approximately 7.389 as e always =2.71828\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact,so reciprocal of counts_sum,for use in normalization\n",
    "probs = counts * counts_sum_inv # will give normalized probabilities by dividing each element by the sum of counts\n",
    "logprobs = probs.log() # will give,this computes the element-wise natural logarithm of the probabilities/ log probabilities\n",
    "loss = -logprobs[range(n), Yb].mean() # This extracts the log probabilities corresponding to the true labels Yb using fancy indexing. \n",
    "#The negative sign and .mean() calculate the average cross-entropy loss over the minibatch\n",
    "#This Cross-entropy loss measures how well the predicted probabilities match the true distribution. A lower cross-entropy loss indicates a better match.\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward() #it triggers the backward pass and compute the gradients of the loss with respect to each parameter in the model\n",
    "loss #printing loss below as tensor\n",
    "#Note- without functions like tanh , sigmoid, model will only provide linear transformation/straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "#This type of manual backpropagation is useful for understanding the details of how gradients flow through the network \n",
    "#during training. However, it's error-prone and usually unnecessary in practice due to the availability of \n",
    "#automatic differentiation in deep learning frameworks like PyTorch\n",
    "\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += (2*bndiff) * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0)\n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "  for j in range(Xb.shape[1]):\n",
    "    ix = Xb[k,j]\n",
    "    dC[ix] += demb[k,j]\n",
    "#cmp('...', ..., ...):A comparison function that prints and compares the gradients for various variables during debugging.    \n",
    "\n",
    "cmp('logprobs', dlogprobs, logprobs) #Calculates the gradient of the log probabilities with respect to the loss.\n",
    "cmp('probs', dprobs, probs) #Uses the chain rule to compute the gradient of the probabilities with respect to the loss.\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)#dcounts_sum_inv, dcounts, dcounts_sum:\n",
    "                                                         #Gradients related to the counts and their sum\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)#dnorm_logits, dlogits, dlogit_maxes:\n",
    "                                             #Gradients related to normalization of logits.\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h) #dh:Gradient with respect to the hidden layer.\n",
    "cmp('W2', dW2, W2)#dW2, db2:Gradients with respect to the parameters of the second linear layer\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)#dhpreact, dbngain, dbnraw, dbnbias, dbndiff, ...:Gradients with respect to batch normalization parameters and intermediate variables.\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)#dembcat, dW1, db1, demb, dC:Gradients related to the embedding/embedding layer\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.492246389389038 diff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "# cross-entropy is commonly used as a loss function to measure the dissimilarity between the predicted probability distribution \n",
    "#and the true distribution (ground truth).\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.05359673500061e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1)# Applies the softmax function to the logits along dimension 1, transforming them into probabilities.\n",
    "#The resulting dlogits tensor now contains the softmax probabilities\n",
    "dlogits[range(n), Yb] -= 1#Calculates the gradient of the cross-entropy loss with respect to the logits. \n",
    "#It subtracts 1 from the element of each row that corresponds to the true class YB\n",
    "dlogits /= n #Normalizes the gradient by dividing it by the number of samples in the batch (n) to compute the average gradient across the batch\n",
    "\n",
    "cmp('logits', dlogits, logits) # Compares the computed gradient (dlogits) with the gradients obtained through automatic differentiation during the forward pass (logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0372, 0.0175, 0.0239, 0.0226, 0.0478, 0.0585, 0.0842, 0.0208, 0.0363,\n",
       "        0.0367, 0.0294, 0.0318, 0.0439, 0.0548, 0.0571, 0.0649, 0.0578, 0.0192,\n",
       "        0.0270, 0.0262, 0.0435, 0.0120, 0.0211, 0.0284, 0.0331, 0.0272, 0.0372],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0] # 1 here is dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0372,  0.0175,  0.0239,  0.0226,  0.0478,  0.0585,  0.0842,  0.0208,\n",
       "         0.0363,  0.0367,  0.0294,  0.0318,  0.0439,  0.0548,  0.0571,  0.0649,\n",
       "         0.0578,  0.0192, -0.9730,  0.0262,  0.0435,  0.0120,  0.0211,  0.0284,\n",
       "         0.0331,  0.0272,  0.0372], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n #n is batch size (32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.8626e-09, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum() # sum of dlogits /= n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2824214a620>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))#figure with dimensions 4 inches by 4 inches\n",
    "plt.imshow(dlogits.detach(), cmap='gray')# Detaching is necessary when working with matplotlib to avoid potential memory leaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "#backprop through batchnorm but all in one go\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape\n",
    "# 32 , the batch size\n",
    "#64, the number of neurons in the hidden layer of the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12297\n",
      "      0/ 200000: 3.6226\n",
      "  10000/ 200000: 2.4935\n",
      "  20000/ 200000: 2.4056\n",
      "  30000/ 200000: 2.0886\n",
      "  40000/ 200000: 1.9836\n",
      "  50000/ 200000: 2.4180\n",
      "  60000/ 200000: 2.2720\n",
      "  70000/ 200000: 2.1422\n",
      "  80000/ 200000: 1.9688\n",
      "  90000/ 200000: 1.9700\n",
      " 100000/ 200000: 2.4428\n",
      " 110000/ 200000: 2.1775\n",
      " 120000/ 200000: 2.1829\n",
      " 130000/ 200000: 2.4737\n",
      " 140000/ 200000: 2.1939\n",
      " 150000/ 200000: 2.3375\n",
      " 160000/ 200000: 2.0872\n",
      " 170000/ 200000: 1.9991\n",
      " 180000/ 200000: 2.3914\n",
      " 190000/ 200000: 1.8835\n"
     ]
    }
   ],
   "source": [
    "# putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "\n",
    "with torch.no_grad(): #this decorator disables gradient tracking\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    # If i is less than 100,000, the learning rate is set to 0.1; otherwise, it is set to 0.01. \n",
    "    #This is a form of step-wise learning rate decay, where the learning rate decreases after a certain number of iterations.\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "# This line updates each parameter using its gradient and the current learning rate.\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print everytime iteration/10000 is leaving 0 remainder\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}') # will print something like 10000/ 200000: 2.3261\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "#meaning you can comment out these 2 lines\n",
    "#    if i % 10000 == 0: # print everytime iteration/10000 is leaving 0 remainder\n",
    "#      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}') # will print something like 10000/ 200000: 2.3261\n",
    "\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for checking your gradients\n",
    "# for p,g in zip(parameters, grads):\n",
    "#   cmp(str(tuple(p.shape)), g, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training  to improve the training stability and speed by normalizing the input to a layer. \n",
    "#During training, BatchNorm normalizes the input of a layer by subtracting the mean and dividing by the standard deviation computed over the current mini-batch\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1 #hpreact represents the pre-activation values in a neural network\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.0722830295562744\n",
      "val 2.1143195629119873\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1 #hpreact represents the pre-activation values in a neural network\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mona.\n",
      "mayah.\n",
      "see.\n",
      "mad.\n",
      "ryla.\n",
      "remmadiendra.\n",
      "gradelynneliah.\n",
      "milopi.\n",
      "eden.\n",
      "sana.\n",
      "arleigh.\n",
      "malaia.\n",
      "noshubergihimier.\n",
      "kindreelynn.\n",
      "noelian.\n",
      "breyce.\n",
      "ryyah.\n",
      "fael.\n",
      "yuma.\n",
      "myston.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
